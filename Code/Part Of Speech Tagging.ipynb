{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import syllables\n",
    "import re\n",
    "import stanza\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stanza.download('en', logging_level='WARN')\n",
    "nlp = stanza.Pipeline('en', logging_level='WARN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv('../Data/train.csv', encoding = 'utf-8', lineterminator=\"\\n\")\n",
    "target = dfTrain['target'].to_frame()\n",
    "target.columns = ['Values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPOS = pd.read_csv('../Data/POS_Columns.csv', encoding = 'utf-8', lineterminator=\"\\n\")\n",
    "cols = ['Index', 'Sents', 'Words', 'C_W_C', 'S_C',\n",
    "                'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET','INTJ', 'NOUN', \n",
    "                'NUM', 'PART', 'PRON','PROPN', 'PUNCT','SCONJ','SYM','VERB','X']\n",
    "dfPOS.columns = cols\n",
    "dfPOS = dfPOS.drop(['Index'], axis = 1)\n",
    "dfPOS = dfPOS.drop(['X'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(doc.sentences))\n",
    "# words = 0\n",
    "# punct = 0\n",
    "# for sentence in doc.sentences:\n",
    "#     pos = []\n",
    "# #     print(sentence)\n",
    "#     words += len(sentence.words)\n",
    "#     for word in sentence.words:\n",
    "#         if word.pos == 'PUNCT':\n",
    "#             punct += 1\n",
    "#         pos.append(word.pos)\n",
    "#         print(word)\n",
    "#     print(pos)\n",
    "# print(words - punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_array = []\n",
    "# def convert_string(excerpt):\n",
    "#     string = ''\n",
    "\n",
    "#     for i in excerpt:\n",
    "#         i = i.replace(\"\\n\", \"\")\n",
    "#         string += i\n",
    "#     return string\n",
    "\n",
    "# for i in X:\n",
    "#     doc = nlp(convert_string(i))\n",
    "#     sentences = len(doc.sentences)\n",
    "#     words = 0\n",
    "#     syllable_count = 0\n",
    "#     complex_word_count = 0\n",
    "#     PartOfSpeech = {i:0 for i in PartOfSpeechTags}\n",
    "#     for sentence in doc.sentences:\n",
    "#         words += len(sentence.words)\n",
    "#         for word in sentence.words:\n",
    "#             PartOfSpeech[word.pos] += 1\n",
    "#             if word.pos != 'PUNCT':\n",
    "#                 syllable_count += syllables.estimate(word.text)\n",
    "#                 if syllables.estimate(word.lemma) >= 3:\n",
    "#                     complex_word_count += 1\n",
    "#     words = words - PartOfSpeech['PUNCT']\n",
    "#     X_array.append([sentences, words, complex_word_count, syllable_count, *PartOfSpeech.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_array = np.array(X_array)\n",
    "# pd.DataFrame(X_array).to_csv('../Data/POS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(reg, dfPOS, targetValues, scoring=\"neg_mean_absolute_error\", cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = - lin_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58748557, 0.71196154, 0.7370633 , 0.71674263, 0.62605086,\n",
       "        0.65625646, 0.68822282, 0.65913333, 0.5167674 , 0.65089023]),\n",
       " 0.6550574135380979,\n",
       " 0.06279724083745164)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_scores, lin_scores.mean(), lin_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.88822063, 0.91902241, 1.00484853, 0.90930802, 0.90282073,\n",
       "        0.90992352, 0.9300873 , 0.89107454, 0.79823857, 0.88698996]),\n",
       " 0.9040534200271748,\n",
       " 0.04799182098221051)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "scores = cross_val_score(tree_reg, dfPOS,targetValues, scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "scores = - scores\n",
    "scores, scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdg_reg = SGDRegressor()\n",
    "scaler = StandardScaler()\n",
    "scaledMetric = scaler.fit_transform(np.array(dfPOS))\n",
    "sdg_reg.fit(scaledMetric, target[\"Values\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58078475, 0.70931378, 0.74131034, 0.72724946, 0.62693891,\n",
       "        0.65613795, 0.70038847, 0.65969366, 0.52062416, 0.65435869]),\n",
       " 0.6576800187294538,\n",
       " 0.06479480259446461)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdg_scores = cross_val_score(sdg_reg, scaledMetric, target[\"Values\"].values, scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "sdg_scores = - sdg_scores\n",
    "sdg_scores, sdg_scores.mean(), sdg_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raffi\\documents\\artificial_intelligence\\artificial_intelligence\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.60565252, 0.69112228, 0.74577564, 0.67986671, 0.6290814 ,\n",
       "        0.63478085, 0.66404986, 0.66024507, 0.53402232, 0.65427444]),\n",
       " 0.6498871081448964,\n",
       " 0.053069078020693466)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor()\n",
    "gb_reg.fit(scaledMetric, targetValues)\n",
    "gb_scores = cross_val_score(gb_reg, scaledMetric, target[\"Values\"].values, scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "gb_scores = - gb_scores\n",
    "gb_scores, gb_scores.mean(), gb_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raffi\\AppData\\Local\\Temp/ipykernel_2912/3409595605.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_reg.fit(scaledMetric, targetValues)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.59430446, 0.68301034, 0.75745108, 0.69180459, 0.6515081 ,\n",
       "        0.6388529 , 0.64387908, 0.66786243, 0.53171851, 0.66102186]),\n",
       " 0.6521413337381655,\n",
       " 0.05659879620916431)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(scaledMetric, targetValues)\n",
    "rf_scores = cross_val_score(rf_reg, scaledMetric, target[\"Values\"].values, scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "rf_scores = - rf_scores\n",
    "rf_scores, rf_scores.mean(), rf_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'predictor__n_estimators': 300}, -0.6493952936725401)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline that combines the preprocessor with linear regression\n",
    "gbs = Pipeline([(\"scaler\", StandardScaler()),\n",
    "    (\"predictor\", GradientBoostingRegressor())])\n",
    "\n",
    "# Create a dictionary of hyperparameters\n",
    "gbs_param_grid = {\"predictor__n_estimators\": [100, 200, 300]}\n",
    "\n",
    "# Create the grid search object which will find the best hyperparameter values based on validation error\n",
    "gbs_gs = GridSearchCV(gbs, gbs_param_grid, scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "\n",
    "# Run grid search by calling fit\n",
    "gbs_gs.fit(dfPOS, target[\"Values\"].values)\n",
    "\n",
    "# Let's see how well we did\n",
    "gbs_gs.best_params_, gbs_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d393923f904ffe42cde0de9f025567d3d3c4600c9e77390da1b0eb8bdd784f4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
